{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Binarized Neural Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code is the implementation used to train a Binarized neural network by encoding it as a MaxSAT problem.\n",
    "\n",
    "The training is based on finding the best W such that an input $x \\in \\{-1,1\\}^n$ is mapped in its corresponding output $y \\in \\{-1,1\\}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pysat.formula import WCNF\n",
    "from pysat.examples.rc2 import RC2\n",
    "import itertools\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to generate a dataset, after having chosen the number of features to use (`n_var`), will be created all the combinations of $\\{-1,1\\}^\\text{n_var}$, concatenated 4 times, shuffled, and finally the corresponding target will be associated by using a boolean function (the one that the BNN will have to approximate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "n_var = 7\n",
    "all_comb = list(itertools.product([-1, 1], repeat=n_var)) * 4\n",
    "np.random.shuffle(all_comb)\n",
    "training_set = all_comb[:int(len(all_comb)*0.6)]\n",
    "test_set = all_comb[int(len(all_comb)*0.6):]\n",
    "# 1 if (x[0] == 1 or x[1] == 1 or x[2] == 1) and (x[3] == 1 or x[4] == -1) and (x[5] == -1 or x[6] == 1) else -1 #49.22%\n",
    "# 1 if (x[0] == 1 and x[1] == 1 or x[2] == 1) and (x[3] == 1 or x[4] == -1) and (x[5] == -1 or x[6] == 1) else -1 #35.16%\n",
    "# 1 if (x[0] == 1 and x[1] == 1 or x[2] == 1) or (x[3] == 1 and x[4] == -1) and (x[5] == -1 or x[6] == 1) else -1 #30.47%\n",
    "# 1 if (x[0] == 1 and x[1] == 1 and x[2] == 1) or (x[3] == 1 or x[4] == -1) and (x[5] == -1 and  x[6] == 1) else -1 #28.91%\n",
    "# 1 if (x[0] == 1 and x[1] == 1 and x[2] == 1) and (x[3] == 1 or x[4] == -1) or (x[5] == -1 and  x[6] == 1) else -1 #32.03%\n",
    "#1 if (x[0] == 1 and x[1] == 1 and x[2] == 1) and (x[3] == 1 and x[4] == -1) or (x[5] == -1 and  x[6] == 1) else -1 #27.34%\n",
    "#1 if (x[0] == 1 or x[1] == 1 and x[2] == 1) and (x[3] == 1 or x[4] == -1) and (x[5] == -1 and  x[6] == 1) and (x[6] == -1 or x[0] == 1) else -1 # 09.38\n",
    "#1 if (x[0] == 1 and x[1] == 1 and x[2] == 1) or (x[3] == 1 and x[4] == -1) and (x[5] == -1 or  x[6] == 1) or (x[6] == -1 and x[0] == 1) else -1 # 45.31\n",
    "dec_func = lambda x : 1 if (x[0] == 1 or x[1] == 1 and x[2] == 1) and (x[3] == 1 or x[4] == -1) and (x[5] == -1 and  x[6] == 1) and (x[6] == -1 or x[0] == 1) else -1 # 09.38\n",
    "train_targets = [\n",
    "    dec_func(x) for x in training_set\n",
    "]\n",
    "test_targets = [\n",
    "    dec_func(x) for x in test_set\n",
    "]\n",
    "if len(training_set[0]) % 2 == 0:\n",
    "    training_set = np.hstack((training_set, np.ones((len(training_set), 1)))).tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code will print the distribution of the targets in the training and test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING set:\n",
      "10.75% are 1\n",
      "89.25% are -1\n",
      "TEST set:\n",
      "07.32% are 1\n",
      "92.68% are -1\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING set:\")\n",
    "print(f\"{np.sum(np.array(train_targets) == 1) / len(train_targets) * 100:05.2f}% are 1\\n{np.sum(np.array(train_targets) == -1) / len(train_targets) * 100:05.2f}% are -1\")\n",
    "print(\"TEST set:\")\n",
    "print(f\"{np.sum(np.array(test_targets) == 1) / len(test_targets) * 100:05.2f}% are 1\\n{np.sum(np.array(test_targets) == -1) / len(test_targets) * 100:05.2f}% are -1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "assert len(training_set) == len(train_targets) and len(training_set) > 0 and len(training_set[0]) > 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the following functions, all the training set and the weights will be mapped to single numbers in $\\mathbb{N}^+ \\slash \\{0\\}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# get the index representing the j-th feature of the sample i\n",
    "def get_index_x_i_j(i, j, padding=0):\n",
    "    global training_set\n",
    "    # first len(training_set[0]) variables are the weights\n",
    "    return i * (len(training_set[0]) + padding) + j + len(training_set[0]) + padding + 1\n",
    "# get the index representing the i-th weight\n",
    "def get_index_weight_i(i):\n",
    "    return i + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code is used to store WCNF with CNF as soft clauses, in order to be able to associate a weight to a whole CNF, and not only to a specific disjunction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class GroupWCNF(object):\n",
    "    def __init__(self):\n",
    "        self.nv = 0\n",
    "        self.hard = []\n",
    "        self.soft = []\n",
    "        self.wght = []\n",
    "\n",
    "    def append(self, clause, weight=None):\n",
    "        if not isinstance(clause, list):\n",
    "            clause = [clause]\n",
    "        for subclause in clause:\n",
    "            if isinstance(subclause, list):\n",
    "                self.nv = max([abs(l) for l in subclause] + [self.nv])\n",
    "            else:\n",
    "                self.nv = max(abs(subclause), self.nv)\n",
    "        if weight:\n",
    "            self.soft.append(list(clause))\n",
    "            self.wght.append(weight)\n",
    "        else:\n",
    "            self.hard.append(list(clause))\n",
    "\n",
    "    def toWCNF(self):\n",
    "        new_soft_clauses = []\n",
    "        new_hard_clauses = self.hard[:]\n",
    "        max_var = self.nv # max_var will be the new variable introduced\n",
    "        for clause in self.soft:\n",
    "            max_var+=1\n",
    "            new_soft_clauses.append([max_var])\n",
    "            for subclause in clause:\n",
    "                new_hard_clauses.append(subclause + [-max_var])\n",
    "        wcnf = WCNF()\n",
    "\n",
    "        wcnf.extend(new_hard_clauses)\n",
    "        wcnf.extend(new_soft_clauses, weights=self.wght)\n",
    "\n",
    "        return wcnf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "nn = GroupWCNF()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "adding the hard clauses (encoding the dataset):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for i in range(len(training_set)):\n",
    "    for j in range(len(training_set[0])):\n",
    "        if training_set[i][j] > 0:\n",
    "            nn.append([get_index_x_i_j(i,j)])\n",
    "        else:\n",
    "            nn.append([-get_index_x_i_j(i,j)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "adding the soft clauses (for each target that the model can predict correctly, will gain weight 1):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 425 ms, sys: 10.8 ms, total: 435 ms\n",
      "Wall time: 435 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(train_targets)):\n",
    "    J = itertools.combinations(range(len(training_set[0])), len(training_set[0]) // 2 + 1)\n",
    "    temp = []\n",
    "    if train_targets[i] < 0 :\n",
    "        for x_i_subset in J:\n",
    "            for comb in itertools.product([-1, 1], repeat=len(x_i_subset)):\n",
    "                temp.append(\n",
    "                    [get_index_x_i_j(i, x_i_subset[idx]) * _not for idx, _not in enumerate(comb)] +\n",
    "                    [get_index_weight_i(x_i_subset[idx]) * _not for idx, _not in enumerate(comb)],\n",
    "                )\n",
    "    elif train_targets[i] > 0:\n",
    "        for x_i_subset in J:\n",
    "            for comb in itertools.product([-1, 1], repeat=len(x_i_subset)):\n",
    "                temp.append(\n",
    "                    [get_index_x_i_j(i, x_i_subset[idx]) * _not for idx, _not in enumerate(comb)] +\n",
    "                    [get_index_weight_i(x_i_subset[idx]) * (_not * -1) for idx, _not in enumerate(comb)]\n",
    "                )\n",
    "    nn.append(temp, weight=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search solution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`RC2` will be used as solver since it outperforms `FM` in almost all the cases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "solver = RC2(nn.toWCNF(), verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 916 ms, sys: 8.3 ms, total: 924 ms\n",
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = solver.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "w = np.sign([model[0:len(training_set[0])]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 0.6221498371335505\n",
      "Accuracy in test: 0.551219512195122\n"
     ]
    }
   ],
   "source": [
    "predict_train = np.sign(np.multiply(training_set, w).sum(1))\n",
    "predict_test = np.sign(np.multiply(test_set, w).sum(1))\n",
    "print(f\"Accuracy in training: {accuracy_score(train_targets, predict_train)}\")\n",
    "print(f\"Accuracy in test: {accuracy_score(test_targets, predict_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Brute forcing weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an alternative, the weights can be brute forced (MaxSAT is NP hard, therefore the worst case complexity is the same).\n",
    "\n",
    "Thanks to the fact that Numpy uses multi threading, this approach is faster when dealing with more than 8 features, or when the target classes are very unbalanced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 0.6221498371335505\n",
      "Accuracy in test: 0.551219512195122\n",
      "CPU times: user 30.7 ms, sys: 1.53 ms, total: 32.2 ms\n",
      "Wall time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best = None\n",
    "best_acc = 0\n",
    "for w in itertools.product([-1,1], repeat=len(training_set[0])):\n",
    "    predict_train = np.sign(np.multiply(training_set, w).sum(1))\n",
    "    acc = accuracy_score(train_targets, predict_train)\n",
    "    if best is None or acc > best_acc:\n",
    "        best = w\n",
    "        best_acc = acc\n",
    "\n",
    "predict_test = np.sign(np.multiply(test_set, best).sum(1))\n",
    "print(f\"Accuracy in training: {best_acc}\")\n",
    "print(f\"Accuracy in test: {accuracy_score(test_targets, predict_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Biases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following section will try to improve the performances of the BNN when dealing with unbalanced classes, by adding biases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "biases_count = int(len(training_set[0]) / 2)\n",
    "biases_count = biases_count + (0 if (len(training_set[0]) + biases_count) % 2 else 1)\n",
    "training_set_bias = np.hstack((training_set, np.ones((len(training_set), biases_count)))).tolist()\n",
    "test_set_bias = np.hstack((test_set, np.ones((len(test_set), biases_count)))).tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 1.52 s, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn = GroupWCNF()\n",
    "for i in range(len(training_set_bias)):\n",
    "    for j in range(len(training_set_bias[0])):\n",
    "        if training_set_bias[i][j] > 0:\n",
    "            nn.append([get_index_x_i_j(i,j, padding=biases_count+1)])\n",
    "        else:\n",
    "            nn.append([-get_index_x_i_j(i,j, padding=biases_count+1)])\n",
    "\n",
    "for i in range(len(train_targets)):\n",
    "    J = itertools.combinations(range(len(training_set_bias[0])), len(training_set_bias[0]) // 2 + 1)\n",
    "    temp = []\n",
    "    if train_targets[i] < 0 :\n",
    "        for x_i_subset in J:\n",
    "            for comb in itertools.product([-1, 1], repeat=len(x_i_subset)):\n",
    "                temp.append(\n",
    "                    [get_index_x_i_j(i, x_i_subset[idx], padding=biases_count+1) * _not for idx, _not in enumerate(comb)] +\n",
    "                    [get_index_weight_i(x_i_subset[idx]) * _not for idx, _not in enumerate(comb)],\n",
    "                )\n",
    "    elif train_targets[i] > 0:\n",
    "        for x_i_subset in J:\n",
    "            for comb in itertools.product([-1, 1], repeat=len(x_i_subset)):\n",
    "                temp.append(\n",
    "                    [get_index_x_i_j(i, x_i_subset[idx], padding=biases_count+1) * _not for idx, _not in enumerate(comb)] +\n",
    "                    [get_index_weight_i(x_i_subset[idx]) * (_not * -1) for idx, _not in enumerate(comb)]\n",
    "                )\n",
    "    nn.append(temp, weight=1)\n",
    "solver = RC2(nn.toWCNF(), verbose=0)\n",
    "model = solver.compute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 0.9153094462540716\n",
      "Accuracy in test: 0.9317073170731708\n"
     ]
    }
   ],
   "source": [
    "w = np.sign([model[0:len(training_set_bias[0])]])\n",
    "predict_train = np.sign(np.multiply(training_set_bias, w).sum(1))\n",
    "predict_test = np.sign(np.multiply(test_set_bias, w).sum(1))\n",
    "print(f\"Accuracy in training: {accuracy_score(train_targets, predict_train)}\")\n",
    "print(f\"Accuracy in test: {accuracy_score(test_targets, predict_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Brute forcing weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 0.9153094462540716\n",
      "Accuracy in test: 0.9317073170731708\n",
      "CPU times: user 498 ms, sys: 4.14 ms, total: 502 ms\n",
      "Wall time: 519 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best = None\n",
    "best_acc = 0\n",
    "for w in itertools.product([-1,1], repeat=len(training_set_bias[0])):\n",
    "    predict_train = np.sign(np.multiply(training_set_bias, w).sum(1))\n",
    "    acc = accuracy_score(train_targets, predict_train)\n",
    "    if best is None or acc > best_acc:\n",
    "        best = w\n",
    "        best_acc = acc\n",
    "\n",
    "predict_test = np.sign(np.multiply(test_set_bias, best).sum(1))\n",
    "print(f\"Accuracy in training: {best_acc}\")\n",
    "print(f\"Accuracy in test: {accuracy_score(test_targets, predict_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with logistic regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to have a better understanding of how difficult is the prediction, the following code will train a Logistic Regression model in order to have a benchmark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training: 1.0\n",
      "Accuracy in test: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(training_set, train_targets)\n",
    "\n",
    "print(f\"Accuracy in training: {clf.score(training_set, train_targets)}\")\n",
    "print(f\"Accuracy in test: {clf.score(test_set, test_targets)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ml-apple-metal",
   "language": "python",
   "display_name": "Python 3.9 (ML lib metal)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}